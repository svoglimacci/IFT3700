{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unbJvDNCRkWR"
   },
   "source": [
    "# IFT 6758 - Assignment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NYfjiSBBRkkz",
    "tags": []
   },
   "source": [
    "## Question 1\n",
    "\n",
    "### a)\n",
    "Begin by using the functions created in `q1.py` to make the data more informative and readable. Specifically, complete the following cells:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from q1 import count_labels, convert_id, convert_ids, contains_label, get_correlation\n",
    "\n",
    "sns.set(style=\"ticks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "k3cbzq-MRp7Y"
   },
   "outputs": [],
   "source": [
    "# Load the `audio_segments.csv` into a DataFrame `df`\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "TTvysi_WTL89"
   },
   "outputs": [],
   "source": [
    "# Add a column corresponding to the count of labels called `label_count`\n",
    "# Here, there is an annoying issue with accessing the positive_labels column\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "_0DftxCDTMHG"
   },
   "outputs": [],
   "source": [
    "# Add a new column called `label_names` with the processed human readable label names instead of label IDS\n",
    "\n",
    "# Print the time taken for this operation (either using the time module or timeit). \n",
    "# Since we are only executing this code once it is relatively fine that it takes a couple of minutes. \n",
    "# However, for a larger dataset, it would be worth the time to speed it up \n",
    "# (for example by creating a ID -> name dictionary once and using that).\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ZYkS4XLuTQRC"
   },
   "outputs": [],
   "source": [
    "# Display the DataFrame and save it to `audio_segments_clean.csv` (without index)\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o6TlARA6TdKW"
   },
   "source": [
    "### b)\n",
    "\n",
    "Next, using the clean DataFrame, complete the following cells to better understand the distribution of labels in the dataset. For each plot below, make sure to include appropriate **axis names** and a **title**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "JENamq5JUeow"
   },
   "outputs": [],
   "source": [
    "# Using seaborn, create a histogram of the label count of the rows in the DataFrame\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the steps below to create a heatmap showing \"correlation\" between different labels. \n",
    "- Specifically, each cell of the heatmap should correspond to the probability that a sample with the corresponding row label also has the corresponding column label. \n",
    "- Just consider the labels [\"Piano\", \"Classical music\", \"Speech\", \"Conversation\", \"Screaming\"]. \n",
    "\n",
    "Your final plot should look something like this:\n",
    "\n",
    "![alt text](images/heatmap.png \"Heatmap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "yJ284gr9Uh7G"
   },
   "outputs": [],
   "source": [
    "labels = [\"Piano\", \"Music\", \"Speech\", \"Conversation\", \"Screaming\"]\n",
    "\n",
    "# There are a couple ways to approach this, the way we recommend here is to first build a 2D grid where each\n",
    "# value is the correlation value between the corresponding row/column using the functions created in q1.py.\n",
    "\n",
    "# TODO\n",
    "        \n",
    "# Then using sns.heatmap, create the heatmap, taking advantage of xticklabels and yticklabels to set the label names\n",
    "# as tick values\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qBnI-CH0VGkm"
   },
   "source": [
    "## Question 2\n",
    "Question 2 has no notebook component, just fill out the `q2.py` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M6EIMwUCMmON"
   },
   "source": [
    "## Question 3\n",
    "\n",
    "Download the audio for the following labels using the function created in `q3.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from q3 import data_pipeline, rename_files, filter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "q5YLBNpYMtyL"
   },
   "outputs": [],
   "source": [
    "# Download \"Cough\"\n",
    "\n",
    "# TODO\n",
    "\n",
    "# Rename to include the start/end times\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "69FxgrpCMzjs"
   },
   "outputs": [],
   "source": [
    "# Download \"Hammer\"\n",
    "\n",
    "# TODO\n",
    "\n",
    "# Rename to include the start/end times\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you've probably noticed, downloading all this audio data is slow (and as such we only required you to download 2 of the labels). In many cases, it is possible to get significant performance increases by using either multiprocessing (https://docs.python.org/3/library/multiprocessing.html) or multithreading (https://docs.python.org/3/library/threading.html) which could for example allow you to download multiple audio files in parallel. \n",
    "\n",
    "As a good rule of thumb, use multithreading when your programs is IO-bound (for example here) and multiprocessing when it is CPU-bound (and thus make use of all the cores of your CPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ier3C8okRGjp"
   },
   "source": [
    "## Question 4\n",
    "For the following cells, use the ID \"0GNNFBrRz1E\". Complete the functions and run the cells provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "UDG5TVBTR7yb"
   },
   "outputs": [],
   "source": [
    "# Play the audio segment in Jupyter using \n",
    "# https://ipython.org/ipython-doc/dev/api/generated/IPython.display.html#IPython.display.Audio\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jb8csrLuT8ej"
   },
   "source": [
    "One way to visualize audio is through the use of mel-spectrograms. At a very high level, Mel-spectrograms convert audio to a 2D image through the use of the Fourier transform (more details can be found here: https://medium.com/analytics-vidhya/understanding-the-mel-spectrogram-fca2afa2ce53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "2NKfcwYDTQl9"
   },
   "outputs": [],
   "source": [
    "stft_hopsize = 128\n",
    "n_fft = 512\n",
    "sample_rate = 16000\n",
    "\n",
    "def to_log_scale(mel: np.ndarray) -> np.ndarray:\n",
    "    mel = np.log(mel + 1e-6)/2.0\n",
    "    return mel\n",
    "\n",
    "def create_mel_spectrogram(mp3_path: str) -> np.ndarray:\n",
    "    \"\"\" \n",
    "    Using librosa (https://librosa.org/doc/main/generated/librosa.feature.melspectrogram.html) write a function\n",
    "    that:\n",
    "    1. Loads in audio from a mp3_path (using librosa)\n",
    "    2. Converts it to a mel-spectrogram (using the parameters provided above)\n",
    "    3. Applies the logscale transformation to the mel-spectrogram (provided above once again)\n",
    "    4. Returns the transformed mel-spectrogram\n",
    "    \n",
    "    Make sure to pass the correct sample rate\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO  \n",
    "\n",
    "create_mel_spectrogram(\"Hammer_cut/0GNNFBrRz1E_40_50_10.mp3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Audio data can also be visualized by looking at the waveform (i.e. as a line plot of the amplitude values). We will combine both visualizations methods below. The resulting plot should look something like:\n",
    "![alt text](images/combined_plot.png \"Combined Plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "PMSzMEAfSG_N"
   },
   "outputs": [],
   "source": [
    "def plot_audio(mp3_path: str) -> None:\n",
    "    \"\"\" \n",
    "    Using matplotlib and create_mel_spectrogram() write a function that takes a mp3_path and plots\n",
    "    both the waveform (line plot of amplitudes) and the mel-spectrogram side-by-side as subplots.\n",
    "    \n",
    "    Use the path as a single main title for both subplots\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO\n",
    "    \n",
    "\n",
    "plot_audio(\"Hammer_cut/0GNNFBrRz1E_40_50_10.mp3\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "8625a912581caad8d2f5c751bfe9fc2f2863ef19c34b4cfe64ba09a57ac03960"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
